{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM45IMSWegI4JyEpbN5QlBV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. Objetivo:\n"," * Implementar uma Rede Neural Recorrente (RNN) simples em Python pra prever a próxima palavra em uma sequência de texto, utilizando biblioteca TensorFlow/Keras.\n"," * Implementar uma Rede Long Short-Term Memory (LSTM) em Python para classificar o sentimento de frases como \"positivo\" ou \"negativo\", utilizando a biblioteca TensorFlow/Keras.\n"],"metadata":{"id":"8krgi_LQCHTr"}},{"cell_type":"markdown","source":["## 2. Etapas de Desenvolvimento (Fluxo do Programa):\n","\n"],"metadata":{"id":"zbJWGdoWIJ12"}},{"cell_type":"markdown","source":["### 2.1. Implementação: RNN Simples para Previsão da Próxima Palavra\n","* Etapa 1: Preparação dos dados: Coletar e pré-processar um corpus de texto para treinamento.\n","* Etapa 2: Construção do modelo RNN: Definir a arquitetura da RNN simples.\n","* Etapa 3: Treinamento do modelo: Treinar a RNN usando o corpus preparado.\n","* Etapa 4: Avaliação do modelo: Avaliar o desempenho da RNN na previsão da próxima palavra.\n","* Etapa 5: Teste do modelo: Testar o modelo com novas frases."],"metadata":{"id":"5VAGnQgKLXO1"}},{"cell_type":"markdown","source":["### 2.2. Implementação 2: LSTMs para Classificação de Sentimentos\n","* Etapa 1: Preparação dos dados: Coletar e pré-processar um conjunto de frases rotulados (positivo/negativo)\n","* Etapa 2: Construção do modelo LSTM: Definir a arquitetura da LSTM.\n","* Etapa 3: Treinamento do modelo: Treinar a LSTM usando os dados rotulados\n","* Etapa 4: Avaliação do modelo: Avaliar desempenho da LSTM na classificação de sentimentos\n","* Etapa 5: Teste do modelo: Testar o modelo com novas fases"],"metadata":{"id":"5a9OK5dsLQ2-"}},{"cell_type":"markdown","source":["# 3. Implementação 1: Modelo de Rede Neural de Recorrência"],"metadata":{"id":"vAJpl_GaLfE0"}},{"cell_type":"markdown","source":["### Passo 1: Configuração de Ambiente no Google Colab"],"metadata":{"id":"rTMejPINLpD0"}},{"cell_type":"code","source":["# Importar bibliotecas necessárias\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","print(\"Bibliotecas importadas com sucesso\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wsmm7ZqBLwDM","executionInfo":{"status":"ok","timestamp":1748208746202,"user_tz":180,"elapsed":10799,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"8ead1d67-df58-4683-bec0-ef5d5455ddd0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Bibliotecas importadas com sucesso\n"]}]},{"cell_type":"markdown","source":["Explicação:\n","* numpy: Para operações numéricas\n","* tensorflow.keras: A API de alto nível para construir e treinar modelos de deep learning\n","* Embedding: Camada que transforma palavras (indices numéricos) em vetores densos\n","* SimpleRNN: A camada de Rede Neural Recorrente mais básica\n","* Dense: Camada neural comum (fully connected layer)\n","* Tokenizer: Para converter texto em sequências de números\n","* pad_sequences: Para garantir que todas as sequências de entrada tenham o mesmo comprimento"],"metadata":{"id":"pWTpLzpKMp-Z"}},{"cell_type":"markdown","source":["### Passo 2: Preparação do Conjunto de Dados"],"metadata":{"id":"hFdCDnZPNWXc"}},{"cell_type":"code","source":["# Conjunto de dados de treinamento (pequeno e simplificado)\n","\n","textos_treinamento = [\n","    \"eu gosto de programar em python\",\n","    \"python é uma linguagem poderosa\",\n","    \"programar é divertido com python\",\n","    \"aprenda python e seja feliz\",\n","    \"gosto de aprender coisas novas\"\n","]\n","print(f\"Textos de treinamento: {textos_treinamento}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLCFWfHYNhTD","executionInfo":{"status":"ok","timestamp":1748208766588,"user_tz":180,"elapsed":61,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"7f13e906-821b-4663-e9db-6545d24d5ce8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Textos de treinamento: ['eu gosto de programar em python', 'python é uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"]}]},{"cell_type":"code","source":["# Inicializar o Tokenizer\n","tokenizer = Tokenizer()\n","\n","# Construir o vocabulário a partir dos textos\n","tokenizer.fit_on_texts(textos_treinamento)\n","\n","# Converter textos em sequências de números\n","sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n","\n","# Imprimir o vocabulário e as sequências geradas\n","print(f\"\\nVocabulário (palavra:índice): {tokenizer.word_index}\")\n","print(f\"Sequencias numéricas dos textos: {sequencias}\")\n","\n","# Calcular o tamanho do vocabulário (+1 para incluir o 0 de padding)\n","\n","total_palavras = len(tokenizer.word_index) + 1\n","print(f\"Tamanho total do vocabulário: {total_palavras}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7UYn5CJN-DL","executionInfo":{"status":"ok","timestamp":1748208768573,"user_tz":180,"elapsed":54,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"8b80ae07-6463-4fe7-e8a9-52b73a0fb5cb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vocabulário (palavra:índice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'é': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'divertido': 11, 'com': 12, 'aprenda': 13, 'e': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n","Sequencias numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 5, 11, 12, 1], [13, 1, 14, 15, 16], [2, 3, 17, 18, 19]]\n","Tamanho total do vocabulário: 20\n"]}]},{"cell_type":"code","source":["# Preparar Entradas (X) e saídas (y) para a previsão da próxima palavra\n","# a entrada (X) será uma sequência de palavras, e a saída (y) será a palavra seguinte\n","# Determninar o comprimento máximo das sequências para padding\n","\n","max_comprimento = max(len(seq) for seq in sequencias)\n","print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n","\n","# Criar pares de entrada (sequencia parcial) e saída (próxima palavra)\n","# Ex: \"eu gosto de programar\" -> \"em\"\n","#  \"eu gosto de programar em\" -> \"python\"\n","\n","entradas_X = []\n","saidas_y = []\n","\n","for seq in sequencias:\n","  for i in range(1, len(seq)):\n","    entradas_X.append(seq[:i]) # A sequencia até a palavra atual\n","    saidas_y.append(seq[i])    # a proxima palavra\n","\n","print(f\"Exemplo de entradas_x (parcial): {entradas_X[0:5]}\")\n","print(f\"Exemplo de entradas_y (parcial): {saidas_y[0:5]}\")\n","\n","# Padronizar o comprimento das sequências de entrada\n","# Todas as sequências de entrada precisam ter o mesmo comprimento para RNN\n","entradas_X_padded = pad_sequences(entradas_X, maxlen=max_comprimento -1, padding='pre')\n","# O maxlen é 'max_comprimento -1 ' porque a saída 'y' é a ultima palavra, então x sempre terá 1 palavra a menos.\n","\n","# Converter as saídas para o formato one-hot encoding\n","# Isso é necessário para a camada de saída da RNN(softmax)\n","saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n","\n","print(f\"\\nExemplo de entradas_x_padded (após padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n","print(f\"\\nExemplo de saidas_y_one_hot (após one-hot encoding): \\n{saidas_y_one_hot[0:5]}\")\n","print(f\"\\nFormato final das entradas (X): {entradas_X_padded.shape}\")\n","print(f\"\\nExemplo final das saídas (y): {saidas_y_one_hot.shape}\")\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz-oNxftPKyh","executionInfo":{"status":"ok","timestamp":1748209289069,"user_tz":180,"elapsed":41,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"c4d63cab-740f-4b1e-a763-fe6abdee4874"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Comprimento máximo das sequências antes do padding: 6\n","Exemplo de entradas_x (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n","Exemplo de entradas_y (parcial): [2, 3, 4, 7, 1]\n","\n","Exemplo de entradas_x_padded (após padding e truncagem): \n","[[0 0 0 0 6]\n"," [0 0 0 6 2]\n"," [0 0 6 2 3]\n"," [0 6 2 3 4]\n"," [6 2 3 4 7]]\n","\n","Exemplo de saidas_y_one_hot (após one-hot encoding): \n","[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n","Formato final das entradas (X): (21, 5)\n","\n","Exemplo final das saídas (y): (21, 20)\n"]}]},{"cell_type":"markdown","source":["Explicação:\n"," * Geração de Pares: (Sequência -> Proxima palavra). Para treinar a RNN a prever a próxima palavra, transformamos cada frase em multiplos pares de (sequencia parcial, proxima palavra)\n"," * pad_sequences: É vital. Como as sequencias parciais têm comprimentos variados, pad_sequences preenche(com zeros, por padrão) as sequencias mais curtas para que todas tenham o mesmo maxlen. O padding: 'pre' significa que os zeros são adicionados no inicio.\n"," * to_categorical: A camada de saida da RNN (com softmax) produz uma probabilidade para cada palavra no vocabulario to_categorical converte o indice da palavra real em um vetor onde apenas a posição da palavra correta é 1 e o resto é 0 (chamado de one-hot encoding)."],"metadata":{"id":"eMPfEpECTVQT"}},{"cell_type":"markdown","source":["## Passo 3: Construção do Modelo RNN"],"metadata":{"id":"s2z47PNnWckd"}},{"cell_type":"code","source":["# Definindo o modelo\n","# Definir a arquitetura do modelo RNN\n","modelo_rnn = Sequential()\n","\n","# Camada de Embedding:\n","# total_palavras: tamanho vocabulario\n","# 10: dimensão do vetor de embedding (quantas características queremos para cada palavra)\n","# input_lenght: comprimento das sequencias de entrada (maxlen - 1)\n","modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_X_padded.shape[1]))\n","\n","# Camada SimpleRNN:\n","# 32: número de unidades (neurônios) na camada recorrente. Este é o tamanho do estado oculto.\n","modelo_rnn.add(SimpleRNN(32))\n","\n","# Camada Densa de Saída:\n","# total_palavras: número de neurônios de saída (um para cada palavra no vocabulário)\n","# activation='softmax': função de ativação para probabilidade (soma 1 para todas as palavras)\n","modelo_rnn.add(Dense(total_palavras, activation='softmax'))\n","\n","# Compilar o modelo\n","modelo_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Exibir um resumo da arquitetura do modelo\n","modelo_rnn.summary()\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"-QCowV5PWboU","executionInfo":{"status":"ok","timestamp":1748209744608,"user_tz":180,"elapsed":122,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"58f22edd-0a51-4d20-9064-d95e48c471ed"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_4\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["Explicação da arquitetura:\n","\n","* Embedding Layer: Essencial em PLN. Ela mapeia cada palavra(representada por seu índice numérico) para um vetor denso de embedding. Este vetor captura relações semânticas entre as palavras. Por exemplo, palavras com significados semelhantes estarão 'proximas' no escopo de embedding.\n","* SimpleRNN Layer: Esta é a camada recorrente. Ela recebe as sequências de embeddings e processa-as passo a passo. O 32 indica a dimensão do vetor de estado oculto (ou seja, a \"memória\" que a RNN carrega ao longo do tempo).\n","* Dense(Output) Layer: Esta camada final recebe o estado oculto final da Simple RNN e o transforma em um vetor de probabilidades onde cada posição corresponde a uma palavra vocabulário. A função softmax garante que a soma dessas probabilidades seja 1."],"metadata":{"id":"9arlLGXGa_ZY"}},{"cell_type":"markdown","source":["##Passo 4: Treinamento do Modelo"],"metadata":{"id":"0swQrDWMb77B"}},{"cell_type":"code","source":["# Treinando o modelo\n","print(\"\\nIniciando o treinamento do modelo RNN...\")\n","modelo_rnn.fit(entradas_X_padded, saidas_y_one_hot, epochs=100, verbose=1)\n","  # epochs: quandas vezes o modelo verá todo o conjunto de dados\n","  # verbose: 1 para mostrar o progresso do treinamento\n","print(\"Treinamento concluído!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAfXlsPBb_Q7","executionInfo":{"status":"ok","timestamp":1748210205124,"user_tz":180,"elapsed":5671,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"4e237650-8045-45bc-d5be-1368fd49a0f8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iniciando o treinamento do modelo RNN...\n","Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2857 - loss: 2.9260\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2857 - loss: 2.9163\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.9063\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.8960\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.8854\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2381 - loss: 2.8744\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2381 - loss: 2.8631\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2381 - loss: 2.8514\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2381 - loss: 2.8393\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2857 - loss: 2.8269\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2857 - loss: 2.8141\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2857 - loss: 2.8009\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2857 - loss: 2.7873\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2857 - loss: 2.7734\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2857 - loss: 2.7592\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2381 - loss: 2.7447\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2381 - loss: 2.7299\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2381 - loss: 2.7148\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2381 - loss: 2.6995\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2381 - loss: 2.6839\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: 2.6680\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2381 - loss: 2.6518\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2381 - loss: 2.6354\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2381 - loss: 2.6185\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2381 - loss: 2.6014\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2381 - loss: 2.5838\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2381 - loss: 2.5658\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2857 - loss: 2.5474\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2857 - loss: 2.5286\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.5093\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.4896\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2857 - loss: 2.4695\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2857 - loss: 2.4489\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2857 - loss: 2.4280\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2857 - loss: 2.4067\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3333 - loss: 2.3850\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3333 - loss: 2.3629\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3333 - loss: 2.3405\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3333 - loss: 2.3179\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3810 - loss: 2.2949\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3810 - loss: 2.2717\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3810 - loss: 2.2482\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3333 - loss: 2.2244\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3333 - loss: 2.2005\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3333 - loss: 2.1764\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3333 - loss: 2.1521\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 2.1276\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3333 - loss: 2.1031\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3333 - loss: 2.0784\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4286 - loss: 2.0537\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4286 - loss: 2.0289\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4286 - loss: 2.0042\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4286 - loss: 1.9794\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4286 - loss: 1.9546\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4762 - loss: 1.9299\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4762 - loss: 1.9052\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4762 - loss: 1.8806\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4762 - loss: 1.8560\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4762 - loss: 1.8315\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5238 - loss: 1.8071\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5238 - loss: 1.7828\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5238 - loss: 1.7586\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5714 - loss: 1.7345\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5714 - loss: 1.7105\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5714 - loss: 1.6866\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5714 - loss: 1.6628\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5714 - loss: 1.6390\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5714 - loss: 1.6154\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5714 - loss: 1.5919\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5714 - loss: 1.5684\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6190 - loss: 1.5451\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6667 - loss: 1.5219\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7619 - loss: 1.4987\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7619 - loss: 1.4757\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7619 - loss: 1.4528\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7619 - loss: 1.4300\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7619 - loss: 1.4074\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7619 - loss: 1.3848\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7619 - loss: 1.3624\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7619 - loss: 1.3402\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8571 - loss: 1.3181\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8571 - loss: 1.2962\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.2745\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.2530\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8571 - loss: 1.2317\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9048 - loss: 1.2106\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9048 - loss: 1.1898\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9048 - loss: 1.1692\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9048 - loss: 1.1488\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9048 - loss: 1.1288\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9048 - loss: 1.1090\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9048 - loss: 1.0895\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9048 - loss: 1.0703\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9048 - loss: 1.0514\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9048 - loss: 1.0328\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9048 - loss: 1.0145\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9048 - loss: 0.9966\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9048 - loss: 0.9789\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9048 - loss: 0.9616\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9048 - loss: 0.9446\n","Treinamento concluído!\n"]}]},{"cell_type":"markdown","source":["## Passo 5: Usar o modelo para Previsão\n","\n"],"metadata":{"id":"sIZIWfvEe76U"}},{"cell_type":"code","source":["# 1. Função de Previsão:\n","\n","def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n","\n","    \"\"\"\n","    Prevê a proxima palavra dado um texto base.\n","    \"\"\"\n","\n","    # Converter o texto base para a sequência numérica\n","    sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n","\n","    # Padronizar o comprimento da sequênca de entrada(precisa ter o mesmo formato que o treinamento)\n","    # Atenção: max_seq_len deve ser o comprimento que as *entradas* foram pad_sequenciadas\n","    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n","\n","    # Fazer a previsão\n","    previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n","\n","    # Obter o índice da palavra com a maior probabilidade\n","    indice_palavra_prevista = np.argmax(previsao_probabilidades)\n","\n","    # Converter o índice de volta para a palavra\n","    for palavra, indice in tokenizer.word_index.items():\n","      if indice == indice_palavra_prevista:\n","        return palavra\n","    return None # Caso a palavra não seja encontrada (improvável com o vocabulário ajustado)\n","\n","# Comprimento de entrada esperado pelo modelo\n","# entradas_X_padded.shape[1] é o maxlen que usamos no pad_sequences para x\n","comprimento_entrada_modelo = entradas_X_padded.shape[1]\n","\n","# Testar o modelo com novas frases\n","print(\"\\n--- Testando com Modelo RNN ---\")\n","\n","texto_teste_1 = \"eu gosto de\"\n","proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n","print(f\"Texto: '{texto_teste_1}' -> Próxima palavra prevista: '{proxima_1}'\")\n","\n","texto_teste_2 = \"python é uma\"\n","proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n","print(f\"Texto: '{texto_teste_2}' -> Próxima palavra prevista: '{proxima_2}'\")\n","\n","texto_teste_3 = \"programar é divertido\"\n","proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n","print(f\"Texto: '{texto_teste_3}' -> Próxima palavra prevista: '{proxima_3}'\")\n","\n","texto_teste_4 = \"aprenda python e\"\n","proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n","print(f\"Texto: '{texto_teste_4}' -> Próxima palavra prevista: '{proxima_4}'\")\n","\n","# Exemplo com palavra fora do vocabulário ou sequecia que o modelo nunca viu antes\n","texto_teste_5 = \"o sol brilha no\" # Palavras \"sol\" e \"brilha\" não estão no vocabulário\n","proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n","print(f\"Texto: '{texto_teste_5}' -> Próxima palavra prevista: '{proxima_5}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZKWrqb0fLiq","executionInfo":{"status":"ok","timestamp":1748211822288,"user_tz":180,"elapsed":418,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"347ba9d3-f8c0-47b2-b9d7-f93515060066"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testando com Modelo RNN ---\n","Texto: 'eu gosto de' -> Próxima palavra prevista: 'programar'\n","Texto: 'python é uma' -> Próxima palavra prevista: 'linguagem'\n","Texto: 'programar é divertido' -> Próxima palavra prevista: 'com'\n","Texto: 'aprenda python e' -> Próxima palavra prevista: 'seja'\n","Texto: 'o sol brilha no' -> Próxima palavra prevista: 'é'\n"]}]},{"cell_type":"markdown","source":["# Implementação 2: Modelo de Rede Neural Rede Long Short-Term Memory"],"metadata":{"id":"FAsw8PcIjWdz"}},{"cell_type":"markdown","source":["## Passo 1: Configuração do Ambiente e Importação de Bibliotecas"],"metadata":{"id":"o79BU0FGjdq4"}},{"cell_type":"code","source":["# Importar bibliotecas necessárias\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\"Bibliotecas importadas com sucesso!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMDwvC9mjjvd","executionInfo":{"status":"ok","timestamp":1748212202437,"user_tz":180,"elapsed":422,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"7a11bd52-e7ad-41fe-9178-41003d1aca05"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Bibliotecas importadas com sucesso!\n"]}]},{"cell_type":"markdown","source":["O que tem de novo aqui?\n","* LSTM: A camada de Rede Long-Short-Term Memory\n","* train_test_split(sklearn): Para dividir o dataset em conjuntos de treinamento e teste\n","* classification_report, confusion_matrix(sklearn): Para avaliar desempenho do modelo\n","* matplotlib.pyplot, seaborn: Para visualização dos resultados."],"metadata":{"id":"7fm8rA8fkVsP"}},{"cell_type":"markdown","source":["## Passo 2: Preparação do Conjunto de Dados e Análise de Sentimentos"],"metadata":{"id":"ulrh4NylkxiK"}},{"cell_type":"code","source":["# Definir o conjunto de dados (Frases e Rótulos) para análise de sentimentos\n","\n","dados_sentimento = [\n","    (\"este filme é ótimo e divertido\", \"positivo\"),\n","    (\"eu adorei o livro, muito bom\", \"positivo\"),\n","    (\"gostei muito da atuação dos atores\", \"positivo\"),\n","    (\"o roteiro é fraco e chato\", \"negativo\"),\n","    (\"não recomendo esse pessimo produto\", \"negativo\"),\n","    (\"uma perda de tempo horrível\", \"negativo\"),\n","    (\"ótimo trabalho, parabéns\", \"positivo\"),\n","    (\"terrível experiência, nunca mais\", \"negativo\"),\n","    (\"excelente serviço, muito eficiente\", \"positivo\"),\n","    (\"que decepção, muito ruim\", \"negativo\"),\n","    (\"aprendizagem de máquina é fascinante\", \"positivo\"),\n","    (\"pln é um campo interessante\", \"positivo\"),\n","    (\"este software travou varias vezes\", \"negativo\"),\n","    (\"a interface é confusa e difícil\", \"negativo\"),\n","    (\"o aplicativo é super útil e rápido\", \"positivo\"),\n","]\n","\n","textos = [dado[0] for dado in dados_sentimento]\n","sentimentos = [dado[1] for dado in dados_sentimento]\n","\n","print(f\"Total de frases: {len(textos)}\")\n","print(f\"Exemplo de textos: {textos[:3]}\")\n","print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZo47IWokw1S","executionInfo":{"status":"ok","timestamp":1748212866514,"user_tz":180,"elapsed":46,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"9b00ae47-08e1-4359-f6d0-92a306a9c4e2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de frases: 15\n","Exemplo de textos: ['este filme é ótimo e divertido', 'eu adorei o livro, muito bom', 'gostei muito da atuação dos atores']\n","Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"]}]},{"cell_type":"code","source":["# mapear sentimentos para números: converter \"positivo\" e \"negativo\" para 0 e 1\n","mapeamento_sentimento = {'negativo': 0, 'positivo': 1}\n","rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n","\n","print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDJYZnoum3rQ","executionInfo":{"status":"ok","timestamp":1748213351531,"user_tz":180,"elapsed":67,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"bb445c18-0170-4279-9dbb-5446b1b55101"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sentimentos mapeados para números: [1 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n"]}]},{"cell_type":"code","source":["# Tokenização de Texto\n","tokenizar = Tokenizer(num_words=None, oov_token=\"<unk>\")\n","  # num_words=None para pegar todo o vocabulário\n","  # oov_token para palavras desconhecidas\n","tokenizer.fit_on_texts(textos)\n","sequencias_numericas = tokenizer.texts_to_sequences(textos)\n","\n","total_palavras_vocab = len(tokenizer.word_index) + 1 # +1 para o 0 de padding/OOV\n","\n","print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n","print(f\"\\nSequencias numéricas das frases: {sequencias_numericas}\")\n","print(f\"\\nTamanho total do vocabulário: {total_palavras_vocab}\")\n","\n","# Padronizar o comprimento das sequências\n","# Encontrar o comprimento da frase mais longa para padronizar\n","max_len = max(len(s) for s in sequencias_numericas)\n","print(f\"\\nComprimento máximo das sequências: {max_len}\")\n","\n","sequencias_padded = pad_sequences(sequencias_numericas, maxlen=max_len, padding='post')  # 'post' para adicionar zero no final\n","print(f\"Sequencias após padding: \\n{sequencias_padded}\")\n","\n","# Dividir os dados em conjunto de treinamento e teste\n","X_treino, X_teste, y_treino, y_teste = train_test_split(\n","    sequencias_padded, rotulos_numericos, test_size=0.2, random_state=42, stratify=rotulos_numericos\n",")\n","\n","print(f\"\\nShape de X_treino: {X_treino.shape}\")\n","print(f\"\\nShape de X_teste: {X_teste.shape}\")\n","print(f\"\\nShape de y_treino: {y_treino.shape}\")\n","print(f\"\\nShape de X_teste: {y_teste.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ve4EeNFFouwB","executionInfo":{"status":"ok","timestamp":1748213962912,"user_tz":180,"elapsed":118,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"52292fcb-974a-4b84-c3ef-a7c4cde5c242"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vocabulário (palavra: índice): {'é': 1, 'e': 2, 'de': 3, 'python': 4, 'muito': 5, 'o': 6, 'eu': 7, 'gosto': 8, 'programar': 9, 'uma': 10, 'divertido': 11, 'este': 12, 'ótimo': 13, 'em': 14, 'linguagem': 15, 'poderosa': 16, 'com': 17, 'aprenda': 18, 'seja': 19, 'feliz': 20, 'aprender': 21, 'coisas': 22, 'novas': 23, 'filme': 24, 'adorei': 25, 'livro': 26, 'bom': 27, 'gostei': 28, 'da': 29, 'atuação': 30, 'dos': 31, 'atores': 32, 'roteiro': 33, 'fraco': 34, 'chato': 35, 'não': 36, 'recomendo': 37, 'esse': 38, 'pessimo': 39, 'produto': 40, 'perda': 41, 'tempo': 42, 'horrível': 43, 'trabalho': 44, 'parabéns': 45, 'terrível': 46, 'experiência': 47, 'nunca': 48, 'mais': 49, 'excelente': 50, 'serviço': 51, 'eficiente': 52, 'que': 53, 'decepção': 54, 'ruim': 55, 'aprendizagem': 56, 'máquina': 57, 'fascinante': 58, 'pln': 59, 'um': 60, 'campo': 61, 'interessante': 62, 'software': 63, 'travou': 64, 'varias': 65, 'vezes': 66, 'a': 67, 'interface': 68, 'confusa': 69, 'difícil': 70, 'aplicativo': 71, 'super': 72, 'útil': 73, 'rápido': 74}\n","\n","Sequencias numéricas das frases: [[12, 24, 1, 13, 2, 11], [7, 25, 6, 26, 5, 27], [28, 5, 29, 30, 31, 32], [6, 33, 1, 34, 2, 35], [36, 37, 38, 39, 40], [10, 41, 3, 42, 43], [13, 44, 45], [46, 47, 48, 49], [50, 51, 5, 52], [53, 54, 5, 55], [56, 3, 57, 1, 58], [59, 1, 60, 61, 62], [12, 63, 64, 65, 66], [67, 68, 1, 69, 2, 70], [6, 71, 1, 72, 73, 2, 74]]\n","\n","Tamanho total do vocabulário: 75\n","\n","Comprimento máximo das sequências: 7\n","Sequencias após padding: \n","[[12 24  1 13  2 11  0]\n"," [ 7 25  6 26  5 27  0]\n"," [28  5 29 30 31 32  0]\n"," [ 6 33  1 34  2 35  0]\n"," [36 37 38 39 40  0  0]\n"," [10 41  3 42 43  0  0]\n"," [13 44 45  0  0  0  0]\n"," [46 47 48 49  0  0  0]\n"," [50 51  5 52  0  0  0]\n"," [53 54  5 55  0  0  0]\n"," [56  3 57  1 58  0  0]\n"," [59  1 60 61 62  0  0]\n"," [12 63 64 65 66  0  0]\n"," [67 68  1 69  2 70  0]\n"," [ 6 71  1 72 73  2 74]]\n","\n","Shape de X_treino: (12, 7)\n","\n","Shape de X_teste: (3, 7)\n","\n","Shape de y_treino: (12,)\n","\n","Shape de X_teste: (3,)\n"]}]},{"cell_type":"markdown","source":["## Passo 3: Construção do Modelo LSTM\n","\n"],"metadata":{"id":"nMi-JavOrF_g"}},{"cell_type":"code","source":["# Definir a arquitetura do modelo LSTM\n","\n","modelo_lstm = Sequential()\n","\n","# Camada de Embedding: Converte os índices numéricos das palavras em vetores densos.\n","# total_palavras_vocab: tamanho do vocabulário\n","# 50: dimensão do vetor de embedding (pode ser ajustado)\n","# input_length: comprimento padronizado das sequencias (max_len)\n","modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n","\n","# Camada LSTM:\n","# 64: número de unidades (neuronios) na camada LSTM. Define o tamanho do estado oculto e da célula de memória.\n","# dropou: Um tipo de regularização para evitar overfitting (descarta aleatoriamente neuronios durante o treinamento)\n","# recurrent_dropout: Dropout aplicado nas conexões recorrentes da LSTM.\n","modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n","\n","# Camada Densa de Saída:\n","# 1: Um único neurônio de saída, pois é um problema de classificação binária (positivo/negativo).\n","# activation='sigmoid': Função de ativação para classificação binária (produz um valor entre 0 e 1).\n","\n","modelo_lstm.add(Dense(1, activation='sigmoid'))\n","\n","# Compilar o modelo\n","modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Exibir um resumo da arquitetura do modelo\n","modelo_lstm.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"id":"0gnds7nirPNX","executionInfo":{"status":"ok","timestamp":1748214602625,"user_tz":180,"elapsed":112,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"a954a380-431e-40a3-ae4f-cd6f0562669f"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_7\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Passo 4: Treinamento e Avaliação do Modelo"],"metadata":{"id":"Y5Nq9crnte2t"}},{"cell_type":"code","source":["# Treinar o modelo\n","print(\"\\nIniciando o treinamento do modelo LSTM...\")\n","\n","historico = modelo_lstm.fit(\n","    X_treino, y_treino,\n","    epochs=50,\n","    batch_size=2,\n","    validation_split=0.1,\n","    verbose=1\n",")\n","\n","  # epochs: número de vezes que o modelo verá todo o conjunto de dados de treinamento\n","  # batch_size: número de amostras por atualização de gradiente.\n","  # validation_split: % dos dados de treino usados para validação durante o treinamento( opcional, mas bom para monitorar o overfitting).\n","print(\"Treinamento concluído!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMpHJuyRtlNO","executionInfo":{"status":"ok","timestamp":1748214855788,"user_tz":180,"elapsed":12794,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"acf1d3dd-1a5d-4242-866f-a96977b44965"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iniciando o treinamento do modelo LSTM...\n","Epoch 1/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.4472 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6929\n","Epoch 2/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9458 - loss: 0.6879 - val_accuracy: 0.5000 - val_loss: 0.6934\n","Epoch 3/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.6831 - val_accuracy: 0.5000 - val_loss: 0.6954\n","Epoch 4/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9667 - loss: 0.6766 - val_accuracy: 0.5000 - val_loss: 0.6971\n","Epoch 5/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.6644 - val_accuracy: 0.5000 - val_loss: 0.6997\n","Epoch 6/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.6491 - val_accuracy: 0.0000e+00 - val_loss: 0.7048\n","Epoch 7/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.6396 - val_accuracy: 0.0000e+00 - val_loss: 0.7170\n","Epoch 8/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.5783 - val_accuracy: 0.0000e+00 - val_loss: 0.7437\n","Epoch 9/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.4647 - val_accuracy: 0.0000e+00 - val_loss: 0.8030\n","Epoch 10/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.3372 - val_accuracy: 0.0000e+00 - val_loss: 0.9438\n","Epoch 11/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.2482 - val_accuracy: 0.0000e+00 - val_loss: 1.2488\n","Epoch 12/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 1.7958\n","Epoch 13/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.0000e+00 - val_loss: 2.4576\n","Epoch 14/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.0000e+00 - val_loss: 3.0806\n","Epoch 15/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 3.5523\n","Epoch 16/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 3.8954\n","Epoch 17/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.0000e+00 - val_loss: 4.1398\n","Epoch 18/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0000e+00 - val_loss: 4.3197\n","Epoch 19/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.0000e+00 - val_loss: 4.4565\n","Epoch 20/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.0000e+00 - val_loss: 4.5627\n","Epoch 21/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0000e+00 - val_loss: 4.6479\n","Epoch 22/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0000e+00 - val_loss: 4.7239\n","Epoch 23/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0000e+00 - val_loss: 4.7902\n","Epoch 24/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.0000e+00 - val_loss: 4.8507\n","Epoch 25/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 4.9063\n","Epoch 26/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 4.9601\n","Epoch 27/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 5.0137\n","Epoch 28/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.0654\n","Epoch 29/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.1134\n","Epoch 30/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.1619\n","Epoch 31/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.0000e+00 - val_loss: 5.2080\n","Epoch 32/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.0528e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2508\n","Epoch 33/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.2937\n","Epoch 34/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.4343e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3367\n","Epoch 35/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.9850e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3829\n","Epoch 36/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.2063e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.4302\n","Epoch 37/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.0000e+00 - val_loss: 5.4756\n","Epoch 38/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.1102e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5151\n","Epoch 39/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.3279e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5544\n","Epoch 40/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.2348e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5940\n","Epoch 41/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.6528e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6315\n","Epoch 42/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.4094e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6650\n","Epoch 43/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.2398e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6968\n","Epoch 44/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.1402e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7308\n","Epoch 45/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.5013e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7636\n","Epoch 46/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.7723e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7975\n","Epoch 47/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.2605e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8305\n","Epoch 48/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.9942e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8610\n","Epoch 49/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.1263e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8912\n","Epoch 50/50\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.1335e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9221\n","Treinamento concluído!\n"]}]},{"cell_type":"code","source":["# Avalia o modelo no conjunto de teste\n","perda, acuracia = modelo_lstm.evaluate(X_teste, y_teste, verbose=0)\n","print(f\"\\nAcurácia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n","print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n","\n","# Fazer previsões no conjunto de teste\n","y_pred_prob = modelo_lstm.predict(X_teste)\n","y_pred_classes = (y_pred_prob > 0.5).astype(int) # Converter probabilidades para 0 ou 1\n","\n","print(\"\\n --- Relatório de Classificação ---\")\n","cm = confusion_matrix(y_teste, y_pred_classes)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negativo', 'positivo'], yticklabels=['negativo', 'positivo'])\n","plt.xlabel('Previsto')\n","plt.ylabel('Real')\n","plt.title('Matriz de confusão')\n","plt.show()\n"],"metadata":{"id":"JOKnPH7Eucr4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Passo 5: Testar o Modelo com Novas Frases"],"metadata":{"id":"KhSrScwRvsAO"}},{"cell_type":"code","source":["# Utilizando o modelo treinado\n","\n","def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n","  \"\"\"\n","  Prevê o sentimento de uma nova frase.\n","\n","  \"\"\"\n","\n","  # Converter a frase para sequencia numerica\n","  sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n","\n","  # Se a frase tem palavras desconhecidas, o tokenizer pode retornar uma lista vazia ou valores 0\n","  if not sequencia_numerica:\n","    print(f\"Aviso: A frase '{frase_nova}' contém apenas palavras desconhecidas.\")\n","    return \"Desconhecido\" # ou outra indicação\n","\n","  sequencia_numerica = sequencia_numerica[0] # Pega a primeira (e única) sequência\n","\n","  # Padronizar o comprimento da sequência de entrada\n","  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n","\n","  # Fazer a previsão (probabilidade)\n","  probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n","\n","  # Inverter o mapeamento para obter o nome do sentimento\n","  mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n","\n","  # Classificar com base no limiar de 0.5\n","\n","  if probabilidade_positiva >= 0.5:\n","    return mapeamento_inverso[1] # 'positivo'\n","  else:\n","    return mapeamento_inverso[0] # 'negativo'\n","\n","# Testar o modelo com novas frases\n","\n","print(\"\\n --- Testando o Modelo LSTM com novas Frases ---\")\n","\n","frase_nova_1 = \"gostei muito do filme, excelente!\"\n","sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: '{sentimento_1}'\")\n","\n","frase_nova_2 = \"odiei o livro, muito entediante\"\n","sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: '{sentimento_1}'\")\n","\n","frase_nova_3 = \"a aula de pln é ótima!\"\n","sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: '{sentimento_3}'\")\n","\n","frase_nova_4 = \"o atendimento foi péssimo\"\n","sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: '{sentimento_4}'\")\n","\n","frase_nova_5 = \"esse produto não vale a pena, é caro\"\n","sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: '{sentimento_5}'\")\n","\n","frase_nova_6 = \"o filme é legal\"\n","sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: '{sentimento_6}'\")\n","\n","frase_nova_7 = \"isso é horrível, que tristeza\"\n","sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n","print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: '{sentimento_7}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrD0SLgXvvkd","executionInfo":{"status":"ok","timestamp":1748216022722,"user_tz":180,"elapsed":2346,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"624dd9f3-d8b7-4728-d13e-8b7fb9ebdf2d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," --- Testando o Modelo LSTM com novas Frases ---\n","Frase: 'gostei muito do filme, excelente!' -> Sentimento previsto: 'positivo'\n","Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: 'positivo'\n","Frase: 'a aula de pln é ótima!' -> Sentimento previsto: 'positivo'\n","Frase: 'o atendimento foi péssimo' -> Sentimento previsto: 'negativo'\n","Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: 'negativo'\n","Frase: 'o filme é legal' -> Sentimento previsto: 'negativo'\n","Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: 'negativo'\n"]}]}]}