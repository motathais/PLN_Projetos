{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMP5VWaUUPaTCe/875cq2MP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Aula 07 - Descoberta de conhecimento\n","\n","* Compreender os conceitos fundamentais de Descoberta de Conhecimento em Textos (Knowledge Discovery in Texts - KDT)\n","* Aplicar técnicas de identificação de Entidades Nomeadas (NER) para extrair informações relevantes de textos.\n","* Explorar métodos de extração de informação e mineração de textos para obter insights valiosos de grandes volumes de dados textuais.\n","\n"],"metadata":{"id":"NbOsE7ntbeYj"}},{"cell_type":"markdown","source":["###Exemplo 01 - NER com spaCy"],"metadata":{"id":"NuO6HbMH6Pi0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mhG9cLo7Z-0","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1743369390260,"user_tz":180,"elapsed":8003,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"b8c6e5ce-27d0-4945-d9f2-df19dcb96e91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"]}],"source":["!pip install spacy"]},{"cell_type":"code","source":["!python -m spacy download pt_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b0HPW2d6Y9v","executionInfo":{"status":"ok","timestamp":1743369436636,"user_tz":180,"elapsed":10300,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"5be04ee8-a056-444c-e3f3-de4e7bd9f64e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pt-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pt-core-news-sm\n","Successfully installed pt-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Carrega o modelo de português\n","\n","nlp = spacy.load(\"pt_core_news_sm\")\n","\n","# Texto de exemplo\n","\n","texto = \"Elon Musk, CEO da Tesla, visitou o Brasil em maio de 2022 para discutir investimentos de R$ 5 bilhôes\"\n","\n","# Processa o texto\n","\n","doc = nlp(texto)\n","\n","# Imprime as entidades identificadas\n","\n","for entidade in doc.ents:\n","  print(f\"{entidade.text} - {entidade.label_}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eA0zUlLC6e4S","executionInfo":{"status":"ok","timestamp":1743369619967,"user_tz":180,"elapsed":645,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"68f85bf1-a12a-4be5-ba27-89e71ee2e5dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Elon Musk - LOC\n","Tesla - ORG\n","Brasil - LOC\n","R$ 5 - MISC\n"]}]},{"cell_type":"markdown","source":["###Exemplo 02 - NER com NLTK"],"metadata":{"id":"YsG4DJte-TiX"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","from nltk.chunk import ne_chunk\n","\n","# baixar pacotes necessários\n","\n","nltk.download('punkt_tab')\n","nltk.download('maxent_ne_chunker_tab')\n","nltk.download('words')\n","nltk.download('averaged_perceptron_tagger_eng')\n","\n","# Texto de exemplo\n","texto = \"Barack Obama foi presidente dos Estados Unidos e ganhou Prêmio Nobel da Paz\"\n","\n","# Tokenização e POS tagging\n","tokens = word_tokenize(texto)\n","tags =  pos_tag(tokens)\n","\n","# Identificação de entidades\n","entidades = ne_chunk(tags)\n","\n","# exibir as entidades reconhecidas\n","print(entidades)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoWqnUpg-ZzX","executionInfo":{"status":"ok","timestamp":1743370740837,"user_tz":180,"elapsed":1877,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"cfcd6627-f3e8-4f2b-9722-8d2e27c1db40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"stream","name":"stdout","text":["(S\n","  (PERSON Barack/NNP)\n","  (ORGANIZATION Obama/NNP)\n","  foi/NN\n","  presidente/NN\n","  dos/NN\n","  (PERSON Estados/NNP Unidos/NNP)\n","  e/NN\n","  ganhou/NN\n","  (PERSON Prêmio/NNP Nobel/NNP)\n","  da/NN\n","  Paz/NN)\n"]}]},{"cell_type":"markdown","source":["###Exemplo 03 - Extraçao de Informações com Expressões Regulares"],"metadata":{"id":"iYqKVCR3_wcd"}},{"cell_type":"code","source":["import re\n","\n","texto = \"O pagamento deve ser feito até 30 de junho de 2025\"\n","\n","# Expressão regular para encontrar datas\n","\n","padrao = r\"\\d{1,2} de [a-zA-Z]+ de \\d{4}\"\n","datas = re.findall(padrao, texto)\n","\n","print(datas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ed34FcT_wBG","executionInfo":{"status":"ok","timestamp":1743371060502,"user_tz":180,"elapsed":45,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"2be0af0e-adbd-4a35-8716-725d5fa1fc72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['30 de junho de 2025']\n"]}]},{"cell_type":"markdown","source":["###Exemplo 04 - Extraçao de Informações com Regras heurísticas e dicionários"],"metadata":{"id":"4PO--LXcA13d"}},{"cell_type":"code","source":["profissoes = [\"engenheiro\", \"cientista de dados\", \"médico\", \"advogado\"]\n","\n","texto = \"João é engenheiro de software e trabalha na Tesla\"\n","\n","for profissao in profissoes:\n","  if profissao in texto:\n","    print(f\"Profissão identificada: {profissao}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXE9ca-EA1g3","executionInfo":{"status":"ok","timestamp":1743371224168,"user_tz":180,"elapsed":10,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"f43b0090-1983-4901-c755-a2a98af444a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Profissão identificada: engenheiro\n"]}]},{"cell_type":"markdown","source":["###Exemplo 05 - Mineração de Textos com Frequencia de palavras e N-gramas"],"metadata":{"id":"FFuQikjoBerg"}},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from collections import Counter\n","\n","# Baixar os pacotes necessários (se ainda não baixou)\n","nltk.download('punkt')\n","\n","texto = \"Mineração de textos envolve análise de palavras, palavras importantes e padrões.\"\n","\n","# Tokenização do texto\n","palavras = nltk.word_tokenize(texto.lower())\n","\n","# Contagem de frequência das palavras\n","frequencia = Counter(palavras)\n","print(frequencia.most_common(5))  # Top 5 palavras mais frequentes\n","\n","# Gerar bigramas\n","bigrams = list(ngrams(palavras, 2))\n","\n","print(bigrams)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtc2av7JBl7z","executionInfo":{"status":"ok","timestamp":1743371972568,"user_tz":180,"elapsed":3473,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"031faf42-b0d4-4d08-d61c-21e1f3a7f71a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('de', 2), ('palavras', 2), ('mineração', 1), ('textos', 1), ('envolve', 1)]\n","[('mineração', 'de'), ('de', 'textos'), ('textos', 'envolve'), ('envolve', 'análise'), ('análise', 'de'), ('de', 'palavras'), ('palavras', ','), (',', 'palavras'), ('palavras', 'importantes'), ('importantes', 'e'), ('e', 'padrões'), ('padrões', '.')]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["###Exemplo 06 - Mineração de Texto"],"metadata":{"id":"8Ep8FzlEC7Lj"}},{"cell_type":"code","source":["!pip install gensim\n","##!pip install --force-reinstall gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Xk-7ZexDAWG","executionInfo":{"status":"ok","timestamp":1743372008215,"user_tz":180,"elapsed":3242,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"589817c6-6b14-47a1-e9ed-9b410a9d7e9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"]}]},{"cell_type":"code","source":["from gensim import corpora, models\n","\n","# Texto de exemplo\n","\n","documentos = [[\"mineração\", \"textos\", \"dados\"],\n","              [\"inteligencia\", \"artificial\", \"aprendizado\"],\n","              [\"dados\", \"aprendizado\", \"estatística\"]]\n","\n","# Criar dicionários e corpus\n","\n","dicionario = corpora.Dictionary(documentos)\n","corpus = [dicionario.doc2bow(texto) for texto in documentos]\n","\n","# Aplicar LDA\n","lda_modelo = models.LdaModel(corpus, num_topics=2, id2word=dicionario)\n","\n","print(lda_modelo.print_topics())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZG14Vd2DJMp","executionInfo":{"status":"ok","timestamp":1743372030405,"user_tz":180,"elapsed":8,"user":{"displayName":"Thais Marques Mota","userId":"12386624318688821183"}},"outputId":"22cfc0a9-3453-4418-9366-e58cc6bcece2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["[(0, '0.176*\"dados\" + 0.170*\"mineração\" + 0.165*\"textos\" + 0.143*\"aprendizado\" + 0.140*\"inteligencia\" + 0.112*\"artificial\" + 0.093*\"estatística\"'), (1, '0.222*\"aprendizado\" + 0.197*\"dados\" + 0.150*\"estatística\" + 0.136*\"artificial\" + 0.113*\"inteligencia\" + 0.093*\"textos\" + 0.089*\"mineração\"')]\n"]}]}]}